import streamlit as st
import pandas as pd
import openai
from io import BytesIO
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document

# Set OpenAI API Key
OPENAI_API_KEY = "<Enter your OpenAI Key>"
openai.api_key = OPENAI_API_KEY

# Streamlit UI setup
st.set_page_config(page_title="Item Similarity Finder")
st.title("üîç Item Similarity Search")
st.subheader("Upload an Excel file and enter an item number to find similar items.")

# Selected columns to match
SELECTED_COLUMNS = [
    "<parts attributes>"
]

# File uploader
uploaded_file = st.file_uploader("Upload Excel file", type=["xls", "xlsx"])

if uploaded_file is not None:
    # Load Excel file into Pandas DataFrame
    df = pd.read_excel(uploaded_file, dtype=str).fillna("")

    # Check for missing columns
    missing_columns = [col for col in SELECTED_COLUMNS if col not in df.columns]
    if missing_columns:
        st.error(f"Missing required columns: {', '.join(missing_columns)}")
    else:
        # User input: Item Number
        item_number = st.text_input("Enter Item Number:")

        if item_number:
            # Find the row corresponding to the input item number
            if item_number in df["Item_number"].values:
                item_data = df[df["Item_number"] == item_number].iloc[0]

                # Function to calculate attribute match percentage for each row based on selected columns
                def compute_attribute_match_percentage(row):
                    matches = sum(
                        str(row[col]) == str(item_data[col]) for col in SELECTED_COLUMNS
                    )
                    return matches / len(SELECTED_COLUMNS)

                # Apply match percentage calculation and filter rows where combined score is greater than 90%
                df["match_percentage"] = df.apply(compute_attribute_match_percentage, axis=1)
                filtered_df = df[df["match_percentage"] >= 0.90].drop(columns=["match_percentage"])

                if not filtered_df.empty:
                    # Convert each row to a document for vector embedding
                    docs = [
                        Document(page_content=str(row[SELECTED_COLUMNS].to_dict()), metadata={"index": idx})
                        for idx, row in filtered_df.iterrows()
                    ]

                    # Create embeddings
                    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
                    vector_db = FAISS.from_documents(docs, embeddings)

                    # Embed the input item
                    query_embedding = embeddings.embed_query(str(item_data[SELECTED_COLUMNS].to_dict()))

                    # Retrieve similar items with their similarity score
                    search_results = vector_db.similarity_search_with_relevance_scores(
                        str(item_data[SELECTED_COLUMNS].to_dict()), k=20
                    )

                    # Collect results with similarity score > 0.90
                    results_data = []
                    for i, (doc, score) in enumerate(search_results):
                        if score > 0.90:
                            idx = doc.metadata["index"]
                            row_data = filtered_df.loc[idx].to_dict()
                            row_data["Similarity Score"] = round(score, 4)
                            row_data["Rank"] = i + 1
                            row_data["Legacy Part Number"] = row_data.get("PART NUMBER LEGACY", "N/A")
                            results_data.append(row_data)

                    # Convert results to a DataFrame
                    results_df = pd.DataFrame(results_data)

                    if not results_df.empty:
                        # Display results in Streamlit as an interactive table
                        st.write("### üîé Most Similar Items (90% Attribute Match & Similarity Score > 0.90):")
                        st.dataframe(results_df)

                         # Convert DataFrame to CSV
                        csv_data = results_df.to_csv(index=False).encode("utf-8")

                        # Create a download button in Streamlit
                        st.download_button(
                        label="Download CSV",
                        data=csv_data,
                        file_name="PartsSearch.csv",
                        mime="text/csv"
                        )

                    else:
                        st.warning("No similar items found with a similarity score greater than 0.90.")
                else:
                    st.warning("No items found that match at least 90% of the selected attributes.")
            else:
                st.error("Item number not found in the dataset.")
